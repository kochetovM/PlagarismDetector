{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "#Functions:\n",
    "    \n",
    "def Add_tuple_to_hashmap(current_dict, ntuple) :\n",
    "    for word in ntuple:\n",
    "        if word not in current_dict.keys():\n",
    "            current_dict[word]={}\n",
    "            current_dict=current_dict[word]\n",
    "        else:\n",
    "            current_dict=current_dict[word]\n",
    "            \n",
    "def Synonyms_Build_sets(syn_dict, line):\n",
    "    for each in line:\n",
    "        set_of_syn=set()\n",
    "        \n",
    "        for syn_word in line:\n",
    "            if syn_word != each : set_of_syn.add(syn_word)\n",
    "        \n",
    "        syn_dict[each]=list_of_syn\n",
    "        \n",
    "    return \n",
    "                \n",
    "\n",
    "def Check_tuple_inF2(ntuple, branch, synonyms_dict):\n",
    "    \n",
    "    for word in ntuple:      \n",
    "        if word in branch: #checking if current word is in the \"hashmap of tuples\" and if yes then pass on to next word in the compared tuple\n",
    "            branch= branch[word]\n",
    "            if branch == {}: return True   ##if we reach end of \"hashset\" it means this  tuple\n",
    "                            # exist in File_2 and we passing True\n",
    "                \n",
    "        elif word in synonyms_dict: #also checking if this current word has a synonyms    \n",
    "                for syn_word in synonyms_dict[word]:\n",
    "                    if syn_word in branch:\n",
    "                        branch= branch[syn_word]\n",
    "                        if branch == {}: return True\n",
    "                        break\n",
    "        else: return False   ##if current word has no synonyms and it is not in the hashset then passing False \n",
    "                        # as this tuple doesn't exist in File_2\n",
    "        \n",
    "    print(\"Something went wrong\")\n",
    "\n",
    "\n",
    "    #Main \n",
    "\n",
    "def Palagarism_Detector(filename_syn, Filename_1, Filename_2):\n",
    "\n",
    "    start = time.time()\n",
    "    N=3 #nubmer of tuple \n",
    "    \n",
    "    # Here down below we will Convert data from Synonyms File to a Hash Map \n",
    "    # where key is a word and the value is set of Synonyms words\n",
    "    synonyms={}\n",
    "    f_syn=open(filename_syn,\"r\")\n",
    "    \n",
    "    for line in f_syn:\n",
    "        words_list=line.lower().replace(\",\", \" \").replace(\";\", \" \").replace(\".\",\" \").split()\n",
    "        Synonyms_Build_list(synonyms, words_list)\n",
    "    \n",
    "    f_syn.close()\n",
    "\n",
    "\n",
    "             ### Brake of FILE-1\n",
    "\n",
    "    # Now We will read File_1 and transform it to main list of all words of File_1\n",
    "    # it will also be in lowercase without comma or dots \n",
    "    \n",
    "    f_1=open(Filename_1,\"r\")\n",
    "\n",
    "    F1_words_list=[]\n",
    "\n",
    "    for line in f_1:\n",
    "        line_list = (line.lower().replace(\",\", \" \").replace(\";\", \" \").replace(\".\",\" \").split())\n",
    "\n",
    "        #now lets add separeted words to our main list of words of file-1\n",
    "        for each_word in line_list:\n",
    "            F1_words_list.append(each_word)\n",
    "\n",
    "    f_1.close()\n",
    "\n",
    "    # we wil not additional transorm our words list of file-1 anymore to split it by n-tuples, \n",
    "    # as in our algorithm we will relise it as a queue where next word in and first word out for each \n",
    "    # tuple compare\n",
    "    \n",
    "            ### Brake of FILE-2\n",
    "\n",
    "    # here we brake File-2 to N-sized hashmap of tuples\n",
    "    # where it brakes to n-tuples and each word of the tuple is linked to next one: \n",
    "    # by key-value: Dict[word_1]: d2:[word_2] : ... d_n[word_N]: None\n",
    "    # It will give us instant search time to find a certain word. \n",
    "\n",
    "\n",
    "        #now lets add split words by tuples and save it to the hashmap \n",
    "    F2_tuples_head={}\n",
    "    ntuple=[]\n",
    "    len_F2=0 #(optional), amount of words of file2, to be able compare complexity of code run\n",
    "\n",
    "    with open(Filename_2, \"r\") as file2:\n",
    "        line = file2.readline()\n",
    "\n",
    "        while line:\n",
    "            words_list = (line.lower().replace(\",\", \" \").replace(\";\", \" \").replace(\".\",\" \").split())\n",
    "            for each in words_list:\n",
    "                len_F2+=1\n",
    "                if len(ntuple) < N : \n",
    "                    ntuple.append(each)\n",
    "                    if len(ntuple) == N : Add_tuple_to_hashmap(F2_tuples_head, ntuple) \n",
    "                else:\n",
    "                    ntuple.append(each)\n",
    "                    ntuple.pop(0)\n",
    "                    Add_tuple_to_hashmap(F2_tuples_head, ntuple)  \n",
    "            line = file2.readline()\n",
    "\n",
    "\n",
    "            \n",
    "            ### Step 2: Search and compare Algorithm:\n",
    "    \n",
    "    #Start\n",
    "    Total_tuple=0\n",
    "    amount_tuple_in=0\n",
    "    \n",
    "    len_F1=len(F1_words_list)\n",
    "    amount_words_F1=len(F1_words_list)\n",
    "    if len_F1 < N or len_F2<N : return print(\"First or Second is too small to compare\")\n",
    "\n",
    "    while len_F1 >= N :\n",
    "                            \n",
    "        if Check_tuple_inF2(F1_words_list[:3], F2_tuples_head, synonyms) :\n",
    "            amount_tuple_in += 1 # if we find this current tuple F1_words_list[:3]  \n",
    "                                # in the second file (F2_tuples_head) then +1\n",
    "            \n",
    "        F1_words_list.pop(0) # - here we going throw  F1_words_list as it would be a queue so\n",
    "                #  like this we can choose and pass on next tuple to \"check\" function in the next cicle\n",
    "        len_F1= len_F1 - 1\n",
    "        Total_tuple+=1  # - amount of all tuples in first file\n",
    "\n",
    "    #End\n",
    "\n",
    "    print(\"Procent of Plagiarism is: \", amount_tuple_in/Total_tuple*100,\"%\" )\n",
    "    \n",
    "    end = time. time()\n",
    "    print(\"Time of script execution\", end - start)\n",
    "    print(\"Amount of words: File_1: \",amount_words_F1,\" File_2: \", len_F2)\n",
    "    \n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *****  Welcome to Plagarism Detector ***** \n",
      "Please enter first file name: \n",
      "text1.txt\n",
      "Please enter second file name: \n",
      "text2.txt\n",
      "Please enter synonyms file name: \n",
      "syn.txt\n",
      "Procent of Plagiarism is:  85.26346506586626 %\n",
      "Time of script execution 0.17662906646728516\n",
      "Amount of words: File_1:  23990  File_2:  20336\n"
     ]
    }
   ],
   "source": [
    "print(\" *****  Welcome to Plagarism Detector ***** \")\n",
    "print(\"Please enter first file name: \")\n",
    "file1=input()\n",
    "print(\"Please enter second file name: \")\n",
    "file2=input()\n",
    "print(\"Please enter synonyms file name: \")\n",
    "synfile=input()\n",
    "\n",
    "Palagarism_Detector(synfile, file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
